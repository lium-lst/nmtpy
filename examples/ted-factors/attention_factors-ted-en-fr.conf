[training]
# Main .py file which will be used for the model
model_type: attention_factors
# how much validation period will we wait
# to do early stopping
patience: 10
# Maximum number of epochs before stopping training
max_epochs: 20
# Validation start in terms of epochs
# validation frequency in terms of minibatch updates
valid_start: 2
valid_freq: 5000
# 0: no, otherwise weight decay factor
#decay-c: 0.0005
#decay-c: 0
decay_c: 0.0001
# -1: no, otherwise maximum gradient norm
clip_c: 1.0
seed: 1234

[model]
# Using the same embedding for output and previous
tied_trg_emb: True
layer_norm: False
# Sort batches by target length or not
#shuffle-mode: trglen
shuffle-mode: None
# 0: no, otherwise dropout probability
dropout: 0.0
#dropout: 0.1
#emb_dropout: 0.2
#ctx_dropout: 0.4
#out_dropout: 0.4

# Embedding vector dimension
embedding_dim: 620

# RNN's hidden layer dimension
rnn_dim: 1000
#rnn-dim: 512
enc_type: gru
dec_type: gru_cond

# Number of jobs while translating
njobs: 15

# adadelta, adam, sgd or rmsprop
optimizer: adadelta

# Learning rate (only for SGD)
lrate: 1

# 0: no, otherwise alpha regularization factor
alpha_c: 0.0

# batch size
batch_size: 80

#Normalization of the cost
norm-cost: False

# Use BLEU as additional validation metric
valid_metric: bleu

# Script to combine output factors or 'eval1' to evaluate just with the first output
factors: eval1

weight_init: xavier

# 0: use all vocabulary, otherwise upper limit as integer
n_words_src: 30000
n_words_trg1: 30000
n_words_trg2: 500

# Where to save model params, weights and training log file
save_path:  /lium/trad5a/iwslt/2015/garcia/en-fr/theano/attention_factors-ted-en-fr

[model.dicts]
src: '/lium/buster1/garcia/workspace/nmtpy_github_lium/nmtpy/examples/ted-factors/data/ted.pre.en.vocab.pkl'
trg1: '/lium/buster1/garcia/workspace/nmtpy_github_lium/nmtpy/examples/ted-factors/data/ted.pre.macaon.lem.fr.vocab.pkl'
trg2: '/lium/buster1/garcia/workspace/nmtpy_github_lium/nmtpy/examples/ted-factors/data/ted.pre.macaon.factors.fr.vocab.pkl'

[model.data]
train_src: '/lium/buster1/garcia/workspace/nmtpy_github_lium/nmtpy/examples/ted-factors/data/ted.pre.en'
train_trg1: '/lium/buster1/garcia/workspace/nmtpy_github_lium/nmtpy/examples/ted-factors/data/ted.pre.macaon.lem.fr'
train_trg2: '/lium/buster1/garcia/workspace/nmtpy_github_lium/nmtpy/examples/ted-factors/data/ted.pre.macaon.factors.fr'
valid_src: '/lium/buster1/garcia/workspace/nmtpy_github_lium/nmtpy/examples/ted-factors/data/liumdev15.pre.en'
valid_trg: '/lium/buster1/garcia/workspace/nmtpy_github_lium/nmtpy/examples/ted-factors/data/liumdev15.pre.fr'
valid_trg1: '/lium/buster1/garcia/workspace/nmtpy_github_lium/nmtpy/examples/ted-factors/data/liumdev15.prep_macaon.lem.fr'
valid_trg2: '/lium/buster1/garcia/workspace/nmtpy_github_lium/nmtpy/examples/ted-factors/data/liumdev15.prep_macaon.factors.fr'

